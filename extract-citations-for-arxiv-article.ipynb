{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-22T19:37:35.579270Z",
     "iopub.status.busy": "2025-05-22T19:37:35.578974Z",
     "iopub.status.idle": "2025-05-22T19:37:35.722631Z",
     "shell.execute_reply": "2025-05-22T19:37:35.721479Z",
     "shell.execute_reply.started": "2025-05-22T19:37:35.579244Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get citation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T19:37:35.724031Z",
     "iopub.status.busy": "2025-05-22T19:37:35.723719Z",
     "iopub.status.idle": "2025-05-22T19:37:35.728981Z",
     "shell.execute_reply": "2025-05-22T19:37:35.727980Z",
     "shell.execute_reply.started": "2025-05-22T19:37:35.723999Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "article_ids = [\"1005.1176\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T19:37:35.731854Z",
     "iopub.status.busy": "2025-05-22T19:37:35.731482Z",
     "iopub.status.idle": "2025-05-22T19:37:35.753760Z",
     "shell.execute_reply": "2025-05-22T19:37:35.752502Z",
     "shell.execute_reply.started": "2025-05-22T19:37:35.731826Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_cite_id(article_ids):\n",
    "    try:        \n",
    "        paper_ids = [f\"ARXIV:{article_id}\" for article_id in article_ids]\n",
    "        \n",
    "        params = {\n",
    "            'fields': 'externalIds,citations.externalIds,citations.year,citations.url',\n",
    "            'offset': 0,\n",
    "            'limit': 50\n",
    "        }\n",
    "        \n",
    "        response = requests.post(\n",
    "            'https://api.semanticscholar.org/graph/v1/paper/batch',\n",
    "            params=params,\n",
    "            json={\"ids\": paper_ids}  \n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            \n",
    "            return data       \n",
    "        else:\n",
    "            print(f\"Request failed with status code {response.status_code} for file {input_file}\")\n",
    "            print(response.text)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T19:37:35.754815Z",
     "iopub.status.busy": "2025-05-22T19:37:35.754546Z",
     "iopub.status.idle": "2025-05-22T19:37:36.133434Z",
     "shell.execute_reply": "2025-05-22T19:37:36.132465Z",
     "shell.execute_reply.started": "2025-05-22T19:37:35.754788Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cite_id_output = get_cite_id(article_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get article_id and citation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T19:37:36.147502Z",
     "iopub.status.busy": "2025-05-22T19:37:36.147170Z",
     "iopub.status.idle": "2025-05-22T19:37:36.171653Z",
     "shell.execute_reply": "2025-05-22T19:37:36.170441Z",
     "shell.execute_reply.started": "2025-05-22T19:37:36.147475Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_article_id_and_citation(data):\n",
    "    for item in data:\n",
    "        if isinstance(item, dict):\n",
    "            articleID = {\n",
    "                \"paperId\": item.get(\"paperId\"),\n",
    "                \"ArXiv\": item.get(\"externalIds\", {}).get(\"ArXiv\")\n",
    "            }\n",
    "            \n",
    "            if articleID[\"paperId\"] and articleID[\"ArXiv\"] and articleID[\"ArXiv\"].strip():\n",
    "                \n",
    "                result = {\n",
    "                    \"articleID\": articleID,\n",
    "                    \"citation\": []\n",
    "                }\n",
    "                \n",
    "                for citation in item.get(\"citations\", []):\n",
    "                    if citation and citation.get(\"externalIds\"):\n",
    "                        arxiv_id = citation[\"externalIds\"].get(\"ArXiv\", \"null\")\n",
    "                    else:\n",
    "                        arxiv_id = \"null\"\n",
    "\n",
    "                    citation_info = {\n",
    "                        \"paperId\": citation.get(\"paperId\"),\n",
    "                        \"ArXiv\": arxiv_id,\n",
    "                        \"year\": citation.get(\"year\", \"null\"),\n",
    "                        \"url\": citation.get(\"url\", \"null\")\n",
    "                    }\n",
    "                    result[\"citation\"].append(citation_info)\n",
    "\n",
    "                try:\n",
    "                    return result\n",
    "                except IOError as e:\n",
    "                    print(f\"Error writing file {file_name}: {e}\")\n",
    "            else:\n",
    "                print(f\"Skipping article due to missing paperId or ArXiv info: {articleID}\")\n",
    "        else:\n",
    "            print(f\"Skipping non-dictionary item: {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T19:37:36.172807Z",
     "iopub.status.busy": "2025-05-22T19:37:36.172542Z",
     "iopub.status.idle": "2025-05-22T19:37:36.195879Z",
     "shell.execute_reply": "2025-05-22T19:37:36.195131Z",
     "shell.execute_reply.started": "2025-05-22T19:37:36.172788Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "article_id_and_citation = get_article_id_and_citation(cite_id_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get citeID with Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T19:37:36.224568Z",
     "iopub.status.busy": "2025-05-22T19:37:36.223906Z",
     "iopub.status.idle": "2025-05-22T19:37:36.240334Z",
     "shell.execute_reply": "2025-05-22T19:37:36.239288Z",
     "shell.execute_reply.started": "2025-05-22T19:37:36.224545Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_cite_id_with_year(data):\n",
    "    article_id = data['articleID']['ArXiv']\n",
    "\n",
    "    citations = data['citation']\n",
    "    filtered_citations = [\n",
    "        citation for citation in citations if citation['ArXiv'] != \"null\"\n",
    "    ]\n",
    "\n",
    "    filtered_citations = sorted(filtered_citations, key=lambda x: x['year'], reverse=True)\n",
    "\n",
    "    result_citations = [citation['ArXiv'] for citation in filtered_citations[:15]]\n",
    "\n",
    "    result = {\n",
    "        'article_id': article_id,\n",
    "        'cite_id': result_citations\n",
    "    }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T19:37:36.241695Z",
     "iopub.status.busy": "2025-05-22T19:37:36.241348Z",
     "iopub.status.idle": "2025-05-22T19:37:36.269097Z",
     "shell.execute_reply": "2025-05-22T19:37:36.268084Z",
     "shell.execute_reply.started": "2025-05-22T19:37:36.241658Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cite_id_with_year = get_cite_id_with_year(article_id_and_citation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get citation to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T19:37:36.291775Z",
     "iopub.status.busy": "2025-05-22T19:37:36.291489Z",
     "iopub.status.idle": "2025-05-22T19:37:36.309507Z",
     "shell.execute_reply": "2025-05-22T19:37:36.308585Z",
     "shell.execute_reply.started": "2025-05-22T19:37:36.291756Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "citation_list = cite_id_with_year['cite_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get information article_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T19:37:36.332678Z",
     "iopub.status.busy": "2025-05-22T19:37:36.332260Z",
     "iopub.status.idle": "2025-05-22T19:37:36.353393Z",
     "shell.execute_reply": "2025-05-22T19:37:36.352664Z",
     "shell.execute_reply.started": "2025-05-22T19:37:36.332653Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_in4_article_id(article_id):\n",
    "    try:\n",
    "        paper_id = f\"ARXIV:{article_id}\"\n",
    "\n",
    "        params = {\n",
    "            'fields': 'externalIds,title,authors,year',\n",
    "            'offset': 0,\n",
    "            'limit': 1\n",
    "        }\n",
    "\n",
    "        response = requests.post(\n",
    "            'https://api.semanticscholar.org/graph/v1/paper/batch',\n",
    "            params=params,\n",
    "            json={\"ids\": [paper_id]}  \n",
    "        )\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "\n",
    "            return data\n",
    "\n",
    "        else:\n",
    "            print(f\"Request failed with status code {response.status_code} for article_id {article_id}\")\n",
    "            print(response.text)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T19:37:36.354845Z",
     "iopub.status.busy": "2025-05-22T19:37:36.354518Z",
     "iopub.status.idle": "2025-05-22T19:37:36.543403Z",
     "shell.execute_reply": "2025-05-22T19:37:36.542588Z",
     "shell.execute_reply.started": "2025-05-22T19:37:36.354814Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "article_id = article_ids[0] \n",
    "in4_article_id = get_in4_article_id(article_id)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge JSON FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T19:37:36.552266Z",
     "iopub.status.busy": "2025-05-22T19:37:36.551990Z",
     "iopub.status.idle": "2025-05-22T19:37:36.569292Z",
     "shell.execute_reply": "2025-05-22T19:37:36.568246Z",
     "shell.execute_reply.started": "2025-05-22T19:37:36.552235Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def process_article_id(article_id):\n",
    "    try:\n",
    "        paper_id = f\"ARXIV:{article_id}\"\n",
    "\n",
    "        params = {\n",
    "            'fields': 'externalIds,title,authors,year',\n",
    "            'offset': 0,\n",
    "            'limit': 1\n",
    "        }\n",
    "\n",
    "        response = requests.post(\n",
    "            'https://api.semanticscholar.org/graph/v1/paper/batch',\n",
    "            params=params,\n",
    "            json={\"ids\": [paper_id]}  \n",
    "        )\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            \n",
    "            if data:\n",
    "                for item in data:\n",
    "                    if item: \n",
    "                        arxiv_id = item.get(\"externalIds\", {}).get(\"ArXiv\", None)\n",
    "                        \n",
    "                        new_item = {\n",
    "                            \"Arxiv\": arxiv_id,  \n",
    "                            \"paperId\": item.get(\"paperId\"),\n",
    "                            \"title\": item.get(\"title\"),\n",
    "                            \"year\": item.get(\"year\"),\n",
    "                            \"authors\": item.get(\"authors\", [])\n",
    "                        }\n",
    "                        \n",
    "                return new_item\n",
    "            else:\n",
    "                print(f\"No data found for article_id: {article_id}\")\n",
    "        else:\n",
    "            print(f\"Request failed with status code {response.status_code}\")\n",
    "            print(response.text)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T19:37:36.570759Z",
     "iopub.status.busy": "2025-05-22T19:37:36.570392Z",
     "iopub.status.idle": "2025-05-22T19:37:36.921404Z",
     "shell.execute_reply": "2025-05-22T19:37:36.920471Z",
     "shell.execute_reply.started": "2025-05-22T19:37:36.570727Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "title_article_id = process_article_id(article_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T19:37:36.930433Z",
     "iopub.status.busy": "2025-05-22T19:37:36.929739Z",
     "iopub.status.idle": "2025-05-22T19:37:36.950842Z",
     "shell.execute_reply": "2025-05-22T19:37:36.949854Z",
     "shell.execute_reply.started": "2025-05-22T19:37:36.930348Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dict_arxiv_cite_id = cite_id_with_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge title with dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T19:37:36.971166Z",
     "iopub.status.busy": "2025-05-22T19:37:36.970756Z",
     "iopub.status.idle": "2025-05-22T19:37:36.988215Z",
     "shell.execute_reply": "2025-05-22T19:37:36.987438Z",
     "shell.execute_reply.started": "2025-05-22T19:37:36.971145Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def merge_title_dict(title_data, dict_data):    \n",
    "    merged_output = {}\n",
    "    # Prepare the merged output\n",
    "    merged_output = {\n",
    "        \"article_id\": title_data,\n",
    "        \"cite_id\": dict_data[\"cite_id\"]\n",
    "    }    \n",
    "    \n",
    "    return merged_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T19:37:36.989796Z",
     "iopub.status.busy": "2025-05-22T19:37:36.989517Z",
     "iopub.status.idle": "2025-05-22T19:37:37.007258Z",
     "shell.execute_reply": "2025-05-22T19:37:37.006505Z",
     "shell.execute_reply.started": "2025-05-22T19:37:36.989777Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "merged_article_cite_id = merge_title_dict(title_article_id, dict_arxiv_cite_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Norm title and dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T19:37:37.030147Z",
     "iopub.status.busy": "2025-05-22T19:37:37.029793Z",
     "iopub.status.idle": "2025-05-22T19:37:37.049518Z",
     "shell.execute_reply": "2025-05-22T19:37:37.048606Z",
     "shell.execute_reply.started": "2025-05-22T19:37:37.030101Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def normalize_json(data):\n",
    "    if 'authors' in data['article_id']:\n",
    "        data['article_id']['authors'] = [author['name'] for author in data['article_id']['authors']]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T19:37:37.050934Z",
     "iopub.status.busy": "2025-05-22T19:37:37.050572Z",
     "iopub.status.idle": "2025-05-22T19:37:37.069653Z",
     "shell.execute_reply": "2025-05-22T19:37:37.068785Z",
     "shell.execute_reply.started": "2025-05-22T19:37:37.050901Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "norm_merged_article_cite_id = normalize_json(merged_article_cite_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T19:37:37.095742Z",
     "iopub.status.busy": "2025-05-22T19:37:37.095475Z",
     "iopub.status.idle": "2025-05-22T19:37:37.120258Z",
     "shell.execute_reply": "2025-05-22T19:37:37.119324Z",
     "shell.execute_reply.started": "2025-05-22T19:37:37.095723Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open(\"normalized_merged_article_cite_id.json\", 'w', encoding='utf-8') as output_f:\n",
    "        json.dump(norm_merged_article_cite_id, output_f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T19:37:37.122121Z",
     "iopub.status.busy": "2025-05-22T19:37:37.121805Z",
     "iopub.status.idle": "2025-05-22T19:37:48.852829Z",
     "shell.execute_reply": "2025-05-22T19:37:48.851591Z",
     "shell.execute_reply.started": "2025-05-22T19:37:37.122097Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!python -m pip install -q --upgrade arxiv-dl\n",
    "!pip -q install paper-cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T19:37:48.854421Z",
     "iopub.status.busy": "2025-05-22T19:37:48.854108Z",
     "iopub.status.idle": "2025-05-22T19:37:48.860077Z",
     "shell.execute_reply": "2025-05-22T19:37:48.859034Z",
     "shell.execute_reply.started": "2025-05-22T19:37:48.854378Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def download_papers(paper_ids, download_dir):\n",
    "    for paper_id in paper_ids:\n",
    "        subprocess.run(['paper', paper_id, '-d', download_dir])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T19:37:48.861379Z",
     "iopub.status.busy": "2025-05-22T19:37:48.861079Z",
     "iopub.status.idle": "2025-05-22T19:37:48.881531Z",
     "shell.execute_reply": "2025-05-22T19:37:48.880538Z",
     "shell.execute_reply.started": "2025-05-22T19:37:48.861335Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "paper_ids = norm_merged_article_cite_id['cite_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-22T19:37:48.883013Z",
     "iopub.status.busy": "2025-05-22T19:37:48.882643Z",
     "iopub.status.idle": "2025-05-22T19:38:14.850917Z",
     "shell.execute_reply": "2025-05-22T19:38:14.849847Z",
     "shell.execute_reply.started": "2025-05-22T19:37:48.882983Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "download_dir = \"PDF\"\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "download_papers(paper_ids, download_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert PDF to XML (Using Grobid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T19:38:14.851790Z",
     "iopub.status.busy": "2025-05-22T19:38:14.851576Z",
     "iopub.status.idle": "2025-05-22T19:38:14.856670Z",
     "shell.execute_reply": "2025-05-22T19:38:14.855665Z",
     "shell.execute_reply.started": "2025-05-22T19:38:14.851774Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "config_path = \"config.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T19:38:14.858445Z",
     "iopub.status.busy": "2025-05-22T19:38:14.857637Z",
     "iopub.status.idle": "2025-05-22T19:38:19.094150Z",
     "shell.execute_reply": "2025-05-22T19:38:19.093108Z",
     "shell.execute_reply.started": "2025-05-22T19:38:14.858420Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!python3 -m pip install grobid-client-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T19:38:19.095634Z",
     "iopub.status.busy": "2025-05-22T19:38:19.095335Z",
     "iopub.status.idle": "2025-05-22T19:38:19.106843Z",
     "shell.execute_reply": "2025-05-22T19:38:19.105890Z",
     "shell.execute_reply.started": "2025-05-22T19:38:19.095606Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from grobid_client.grobid_client import GrobidClient, ServerUnavailableException  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T19:38:19.108096Z",
     "iopub.status.busy": "2025-05-22T19:38:19.107804Z",
     "iopub.status.idle": "2025-05-22T19:38:19.127579Z",
     "shell.execute_reply": "2025-05-22T19:38:19.126627Z",
     "shell.execute_reply.started": "2025-05-22T19:38:19.108070Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def process_batches(config_path, input_folder, output_folder, num_files_per_batch=50, max_retries=3):\n",
    "    \"\"\"\n",
    "    Process batches using GROBID.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = GrobidClient(config_path=config_path)\n",
    "    except ServerUnavailableException:\n",
    "        print(\"Error: Unable to connect to the GROBID server.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error during client initialization: {e}\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            client.process(\n",
    "                \"processFulltextDocument\",\n",
    "                input_folder,\n",
    "                output=output_folder,\n",
    "                n=num_files_per_batch,\n",
    "                segment_sentences=True\n",
    "            )\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Error during processing (attempt {attempt + 1}/{max_retries}): {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                print(\"Retrying...\")\n",
    "                time.sleep(60)\n",
    "            else:\n",
    "                print(f\"Skipping batch after {max_retries} failed attempts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T19:38:19.128840Z",
     "iopub.status.busy": "2025-05-22T19:38:19.128522Z",
     "iopub.status.idle": "2025-05-22T19:38:19.155137Z",
     "shell.execute_reply": "2025-05-22T19:38:19.154002Z",
     "shell.execute_reply.started": "2025-05-22T19:38:19.128812Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "input_folder = \"PDF\"\n",
    "output_folder = \"XML\"\n",
    "process_batches(config_path, input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get citing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get citing from XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T19:38:19.156617Z",
     "iopub.status.busy": "2025-05-22T19:38:19.156319Z",
     "iopub.status.idle": "2025-05-22T19:38:19.176674Z",
     "shell.execute_reply": "2025-05-22T19:38:19.175411Z",
     "shell.execute_reply.started": "2025-05-22T19:38:19.156596Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T19:39:58.539939Z",
     "iopub.status.busy": "2025-05-22T19:39:58.539647Z",
     "iopub.status.idle": "2025-05-22T19:39:58.544400Z",
     "shell.execute_reply": "2025-05-22T19:39:58.543415Z",
     "shell.execute_reply.started": "2025-05-22T19:39:58.539921Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "input_dir = \"XML\"\n",
    "output_file = 'citation_arxiv.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-22T19:38:19.198498Z",
     "iopub.status.idle": "2025-05-22T19:38:19.199002Z",
     "shell.execute_reply": "2025-05-22T19:38:19.198680Z",
     "shell.execute_reply.started": "2025-05-22T19:38:19.198661Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calculate_label_ref(ref_positions, sent):\n",
    "    \"\"\"\n",
    "    Tính toán nhãn label_ref dựa trên khoảng cách giữa các tham chiếu trong câu văn.\n",
    "\n",
    "    :param ref_positions: Danh sách các ref_id trong câu (ví dụ: [\"b42\", \"b41\", \"b29\"]).\n",
    "    :param sent: Câu văn chứa các thẻ tham chiếu.\n",
    "    :return: nhãn label_ref (0, 1, 2, hoặc 3).\n",
    "    \"\"\"\n",
    "    if not ref_positions:\n",
    "        return None  \n",
    "\n",
    "    refs_in_sentence = re.findall(r'\\[#([a-zA-Z0-9]+)\\]', sent)\n",
    "\n",
    "    ref_positions_actual = []\n",
    "    for ref in ref_positions:\n",
    "        if ref in refs_in_sentence:\n",
    "            ref_positions_actual.append(ref)\n",
    "    \n",
    "    if not ref_positions_actual:\n",
    "        return None\n",
    "\n",
    "    ref_positions_data = []\n",
    "    for ref in ref_positions_actual:\n",
    "        start_pos = sent.find(f\"[#{ref}]\")\n",
    "        end_pos = start_pos + len(f\"[#{ref}]\") - 1\n",
    "        ref_positions_data.append((ref, start_pos, end_pos))\n",
    "    \n",
    "    distances = []\n",
    "    for i in range(len(ref_positions_data) - 1):\n",
    "        ref_1, start_1, end_1 = ref_positions_data[i]\n",
    "        ref_2, start_2, end_2 = ref_positions_data[i + 1]\n",
    "\n",
    "        distance = start_2 - (end_1 + 1)\n",
    "        distances.append(distance)\n",
    "\n",
    "    if len(ref_positions_data) == 1:\n",
    "        label_ref = 0  \n",
    "    elif len(ref_positions_data) > 1:\n",
    "        if all(d <= 1 for d in distances):\n",
    "            label_ref = 1  \n",
    "        elif all(d > 1 <= 1 for d in distances):\n",
    "            label_ref = 2 \n",
    "        else:\n",
    "            label_ref = 3  \n",
    "\n",
    "    return label_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-22T19:38:19.200236Z",
     "iopub.status.idle": "2025-05-22T19:38:19.200593Z",
     "shell.execute_reply": "2025-05-22T19:38:19.200451Z",
     "shell.execute_reply.started": "2025-05-22T19:38:19.200436Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_citations(input_file):\n",
    "    cite_id = os.path.basename(input_file).split('_')[0]  # Extract citation ID from filename\n",
    "    citation_sentences = []\n",
    "    references = {}\n",
    "\n",
    "    ns = {'tei': 'http://www.tei-c.org/ns/1.0'}\n",
    "\n",
    "    tree = ET.parse(input_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    def clean_sentence_text(sentence, ns):\n",
    "        refs = sentence.findall('.//tei:ref[@type=\"bibr\"]', ns)\n",
    "        sentence_text = ET.tostring(sentence, encoding='unicode', method='text').strip()\n",
    "\n",
    "        for ref in refs:\n",
    "            target = ref.get('target')\n",
    "            ref_text = ref.text if ref.text else ''\n",
    "            if target:\n",
    "                sentence_text = sentence_text.replace(f\"{ref_text}\", f\"[{target}]\")\n",
    "\n",
    "        return sentence_text.strip()\n",
    "\n",
    "    for biblStruct in root.findall('.//tei:listBibl/tei:biblStruct', ns):\n",
    "        ref_id = biblStruct.get('{http://www.w3.org/XML/1998/namespace}id')\n",
    "        title_analytic = biblStruct.find('.//tei:analytic/tei:title[@type=\"main\"]', ns)\n",
    "        title_monogr = biblStruct.find('.//tei:monogr/tei:title[@type=\"main\"]', ns)\n",
    "        if title_analytic is not None:\n",
    "            title = title_analytic.text\n",
    "        elif title_monogr is not None:\n",
    "            title = title_monogr.text\n",
    "        else:\n",
    "            title = \"No title\"\n",
    "        \n",
    "        authors = []\n",
    "        for author in biblStruct.findall('.//tei:analytic/tei:author/tei:persName', ns):\n",
    "            surname = author.find('tei:surname', ns).text if author.find('tei:surname', ns) is not None else \"\"\n",
    "            forename = author.find('tei:forename', ns).text if author.find('tei:forename', ns) is not None else \"\"\n",
    "            authors.append(f\"{forename} {surname}\".strip())\n",
    "        \n",
    "        year = biblStruct.find('.//tei:imprint/tei:date[@type=\"published\"]', ns).get('when') if biblStruct.find('.//tei:imprint/tei:date[@type=\"published\"]', ns) is not None else \"Unknown Year\"\n",
    "        \n",
    "        arxiv_id = biblStruct.find('.//tei:idno[@type=\"arXiv\"]', ns)\n",
    "        if arxiv_id is not None:\n",
    "            arxiv_id = arxiv_id.text\n",
    "        else:\n",
    "            arxiv_id = \"No arXiv ID\"\n",
    "            idno_alternate = biblStruct.find('.//tei:idno', ns)\n",
    "            if idno_alternate is not None:\n",
    "                arxiv_id = idno_alternate.text\n",
    "                \n",
    "        references[ref_id] = {\n",
    "            \"id\": ref_id,\n",
    "            \"title\": title,\n",
    "            \"authors\": authors,\n",
    "            \"year\": year,\n",
    "            \"arXiv\": arxiv_id\n",
    "        }\n",
    "\n",
    "    number = 0\n",
    "    for body in root.findall('.//tei:body', ns):\n",
    "        for paragraph in body.findall('.//tei:p', ns):\n",
    "            sentences = paragraph.findall('.//tei:s', ns)\n",
    "            \n",
    "            for i, sentence in enumerate(sentences):\n",
    "                sent_text = ET.tostring(sentence, encoding='unicode', method='text').strip()\n",
    "                refs = sentence.findall('.//tei:ref[@type=\"bibr\"]', ns)\n",
    "                ref_ids = [ref.get('target').replace('#', '') for ref in refs if ref.get('target') is not None]\n",
    "                cleaned_sent_text = clean_sentence_text(sentence, ns)\n",
    "\n",
    "                sent_before = (\n",
    "                    clean_sentence_text(sentences[i - 1], ns) if i > 0 else None\n",
    "                )\n",
    "                sent_after = (\n",
    "                    clean_sentence_text(sentences[i + 1], ns) if i < len(sentences) - 1 else None\n",
    "                )\n",
    "\n",
    "                merge_sent = f\"{sent_before if sent_before else ''} {cleaned_sent_text} {sent_after if sent_after else ''}\".strip()\n",
    "\n",
    "                label_ref = calculate_label_ref(ref_ids, cleaned_sent_text)\n",
    "                if refs:  \n",
    "                    number += 1\n",
    "                    sentence_references = [\n",
    "                        references.get(ref_id, {\"id\": ref_id, \"title\": \"Unknown\", \"authors\": [], \"year\": \"Unknown Year\"})\n",
    "                        for ref_id in ref_ids\n",
    "                    ]\n",
    "\n",
    "                    citation_sentences.append({\n",
    "                        \"Number\": number,\n",
    "                        \"sent\": cleaned_sent_text,\n",
    "                        \"sent_before\": sent_before,\n",
    "                        \"sent_after\": sent_after,\n",
    "                        \"merge_sent\": merge_sent,\n",
    "                        \"ids\": ref_ids,\n",
    "                        \"label\": label_ref,\n",
    "                        \"references\": sentence_references,\n",
    "                    })\n",
    "\n",
    "    return cite_id, citation_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-22T19:38:19.202520Z",
     "iopub.status.idle": "2025-05-22T19:38:19.202834Z",
     "shell.execute_reply": "2025-05-22T19:38:19.202703Z",
     "shell.execute_reply.started": "2025-05-22T19:38:19.202690Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def process_directory(input_dir):\n",
    "    all_citations = []\n",
    "    for root, dirs, files in os.walk(input_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.xml'):\n",
    "                input_file = os.path.join(root, file)\n",
    "                cite_id, citation_sentences = extract_citations(input_file)\n",
    "                all_citations.append({\n",
    "                    \"cite_id\": cite_id,\n",
    "                    \"citation_sentences\": citation_sentences\n",
    "                })\n",
    "\n",
    "    return all_citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-22T19:38:19.204221Z",
     "iopub.status.idle": "2025-05-22T19:38:19.204577Z",
     "shell.execute_reply": "2025-05-22T19:38:19.204449Z",
     "shell.execute_reply.started": "2025-05-22T19:38:19.204432Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def update_json_file(output_file, new_data):\n",
    "    if os.path.exists(output_file):\n",
    "        with open(output_file, 'r', encoding='utf-8') as json_file:\n",
    "            try:\n",
    "                existing_data = json.load(json_file)\n",
    "            except json.JSONDecodeError:\n",
    "                existing_data = []  \n",
    "    else:\n",
    "        existing_data = []\n",
    "\n",
    "    existing_data.extend(new_data)\n",
    "\n",
    "    with open(output_file, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(existing_data, json_file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-22T19:38:19.206396Z",
     "iopub.status.idle": "2025-05-22T19:38:19.206857Z",
     "shell.execute_reply": "2025-05-22T19:38:19.206730Z",
     "shell.execute_reply.started": "2025-05-22T19:38:19.206714Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Process the input directory\n",
    "all_citations = process_directory(input_dir)\n",
    "# Update the JSON file with new data without overwriting the old data\n",
    "update_json_file(output_file, all_citations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge citing and cited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-22T19:38:19.208137Z",
     "iopub.status.idle": "2025-05-22T19:38:19.208518Z",
     "shell.execute_reply": "2025-05-22T19:38:19.208303Z",
     "shell.execute_reply.started": "2025-05-22T19:38:19.208288Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def normalize_author_name(author_name):\n",
    "    author_name = author_name.strip().lower()\n",
    "\n",
    "    parts = author_name.split()\n",
    "\n",
    "    if len(parts[0]) == 1:\n",
    "        parts[0] = parts[0].upper() #+ \".\"\n",
    "\n",
    "    normalized_name = \" \".join([part.capitalize() for part in parts])\n",
    "\n",
    "    return normalized_name\n",
    "\n",
    "def normalize_authors(authors_list):\n",
    "    norm_author_name = [normalize_author_name(author) for author in authors_list if isinstance(author, str)]\n",
    "    \n",
    "    ref_authors_dot = []\n",
    "    for author in norm_author_name:\n",
    "        parts = author.split()\n",
    "        if len(parts[0]) == 1:\n",
    "            ref_authors_dot.append(parts[0].upper() + \".\" + \" \" + \" \".join(parts[1:]))\n",
    "        else:\n",
    "            ref_authors_dot.append(author)\n",
    "\n",
    "    return norm_author_name, ref_authors_dot\n",
    "\n",
    "def authors_match(ref_authors, article_authors):\n",
    "    if not ref_authors or not article_authors:\n",
    "        return False\n",
    "    \n",
    "    ref_authors_norm, ref_authors_dot = normalize_authors(ref_authors)\n",
    "\n",
    "    article_authors_norm, _ = normalize_authors(article_authors)\n",
    "\n",
    "    for author in ref_authors_dot: \n",
    "        if author in article_authors_norm:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def map_citation_sentences(file1_path, file2_path, output_file):\n",
    "    with open(file1_path, 'r', encoding='utf-8') as f1:\n",
    "        data_file1 = json.load(f1)\n",
    "    \n",
    "    with open(file2_path, 'r', encoding='utf-8') as f2:\n",
    "        data_file2 = json.load(f2)\n",
    "    \n",
    "    for article in data_file2:\n",
    "        article_id = article['article_id']\n",
    "        article_arxiv_id = article_id.get(\"Arxiv\")\n",
    "        article_authors = article_id.get(\"authors\", [])  \n",
    "        cite_ids = article.get(\"cite_id\", [])\n",
    "        \n",
    "        article_citation_sentences = []\n",
    "        \n",
    "        for cite_id in cite_ids:\n",
    "            citing_sentences = []\n",
    "\n",
    "            for item in data_file1:\n",
    "                if item[\"cite_id\"] == cite_id:\n",
    "                    for sentence in item.get(\"citation_sentences\", []):\n",
    "                        matching_references = []\n",
    "                        reference_ids = []\n",
    "                        for ref in sentence.get(\"references\", []):\n",
    "                            ref_arxiv_id = ref.get(\"arXiv\")\n",
    "                            ref_authors = ref.get(\"authors\", [])\n",
    "                            ref_title = ref.get(\"title\", \"\")\n",
    "\n",
    "                            ref_id = ref.get(\"id\")\n",
    "                            \n",
    "                            article_arxivID = f\"arXiv:{article_arxiv_id}\"\n",
    "                            \n",
    "                            if (ref_arxiv_id == article_arxiv_id or ref_arxiv_id == article_arxivID) or authors_match(ref_authors, article_authors) or (ref_title in [author for author in article_authors]):\n",
    "                                matching_references.append(ref)\n",
    "                                reference_ids.append(ref_id)\n",
    "            \n",
    "                        if matching_references:\n",
    "                            citing_sentences.append({\n",
    "                                \"sent\": sentence[\"sent\"],\n",
    "                                \"id\": reference_ids \n",
    "                            })\n",
    "            \n",
    "            if citing_sentences:\n",
    "                article_citation_sentences.append({\n",
    "                    \"cite_id\": cite_id,\n",
    "                    \"citing_sentences\": citing_sentences\n",
    "                })\n",
    "        \n",
    "        if article_citation_sentences:\n",
    "            article[\"citation_sentences\"] = article_citation_sentences\n",
    "\n",
    "    with open(output_file, 'w', encoding='utf-8') as output_f:\n",
    "        json.dump(data_file2, output_f, ensure_ascii=False, indent=4)\n",
    "    print(f\"Data merged and saved into {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-22T19:38:19.210550Z",
     "iopub.status.idle": "2025-05-22T19:38:19.210842Z",
     "shell.execute_reply": "2025-05-22T19:38:19.210722Z",
     "shell.execute_reply.started": "2025-05-22T19:38:19.210709Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Đường dẫn tới file JSON input\n",
    "file1_path = 'citation_arxiv.json'  # Citation\n",
    "file2_path = \"normalized_merged_article_cite_id.json\"  # dict{article_id, cite_id}\n",
    "output_file_1 = \"merged_output_ref_arxiv_author_title.json\" \n",
    "\n",
    "# Thực hiện hàm\n",
    "map_citation_sentences(file1_path, file2_path, output_file_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-22T19:38:19.211994Z",
     "iopub.status.idle": "2025-05-22T19:38:19.212380Z",
     "shell.execute_reply": "2025-05-22T19:38:19.212232Z",
     "shell.execute_reply.started": "2025-05-22T19:38:19.212215Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def update_label_ref(citing_sentences):\n",
    "    for citing_sentence in citing_sentences:\n",
    "        sent = citing_sentence['sent']\n",
    "        ids = citing_sentence['id']\n",
    "\n",
    "        all_ids_in_sent = re.findall(r'\\[#(\\w+)\\]', sent)\n",
    "\n",
    "        if len(ids) == 1:\n",
    "            id = ids[0]\n",
    "            positions = [m.start() for m in re.finditer(r'\\[#' + re.escape(id) + r'\\]', sent)]\n",
    "        \n",
    "            has_only_one_tag = len(all_ids_in_sent) == 1\n",
    "\n",
    "            is_surrounded_by_text = all(\n",
    "                (\n",
    "                    (pos > 0 and sent[pos - 1] == ']') and  \n",
    "                    (pos + len(id) + 3 < len(sent) and sent[pos + len(id) + 3] == '[')  \n",
    "                )\n",
    "                for pos in positions\n",
    "            )\n",
    "\n",
    "            for pos in positions:\n",
    "                prev_char = sent[pos - 1] if pos > 0 else \"N/A\"\n",
    "                prev_condition = (prev_char == ']')\n",
    "       \n",
    "                next_char = sent[pos + len(id) + 3] if pos + len(id) + 3 < len(sent) else \"N/A\"\n",
    "                next_condition = (next_char == '[')\n",
    " \n",
    "            if has_only_one_tag:\n",
    "                citing_sentence['label_ref'] = 0\n",
    "            elif is_surrounded_by_text:\n",
    "                citing_sentence['label_ref'] = 1\n",
    "            else:\n",
    "                citing_sentence['label_ref'] = 2\n",
    "\n",
    "        elif len(ids) > 1:\n",
    "            found_adjacent = False\n",
    "            for id in ids:\n",
    "                positions = [m.start() for m in re.finditer(r'\\[#' + re.escape(id) + r'\\]', sent)]\n",
    "\n",
    "                for pos in positions:\n",
    "                    for other_id in all_ids_in_sent:\n",
    "                        if other_id != id:\n",
    "                            other_positions = [m.start() for m in re.finditer(r'\\[#' + re.escape(other_id) + r'\\]', sent)]\n",
    "\n",
    "                            for other_pos in other_positions:\n",
    "                                if abs(other_pos - pos) == len(id) + 3:  \n",
    "                                    citing_sentence['label_ref'] = 1\n",
    "                                    found_adjacent = True\n",
    "                                    break\n",
    "                            if found_adjacent:\n",
    "                                break\n",
    "                    if found_adjacent:\n",
    "                        break\n",
    "                if found_adjacent:\n",
    "                    break\n",
    "\n",
    "            if not found_adjacent:\n",
    "                citing_sentence['label_ref'] = 2\n",
    "\n",
    "        if 'label_ref' not in citing_sentence:\n",
    "            citing_sentence['label_ref'] = 2\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-22T19:38:19.213867Z",
     "iopub.status.idle": "2025-05-22T19:38:19.214225Z",
     "shell.execute_reply": "2025-05-22T19:38:19.214066Z",
     "shell.execute_reply.started": "2025-05-22T19:38:19.214049Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def process_json(input_file):\n",
    "    with open(input_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    for article in data:\n",
    "        for citation_sentence in article.get(\"citation_sentences\", []):\n",
    "            update_label_ref(citation_sentence[\"citing_sentences\"])\n",
    "\n",
    "    with open(\"label_ref_merged_output_ref_arxiv_author_title.json\", 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "process_json(\"merged_output_ref_arxiv_author_title.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-22T19:38:19.216077Z",
     "iopub.status.idle": "2025-05-22T19:38:19.216461Z",
     "shell.execute_reply": "2025-05-22T19:38:19.216279Z",
     "shell.execute_reply.started": "2025-05-22T19:38:19.216260Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def conv_with_group(file_input, file_output):\n",
    "    import json\n",
    "\n",
    "    with open(file_input, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    dicts = []\n",
    "    number = 0\n",
    "\n",
    "    for item in data:\n",
    "        article_citation_sentences = []\n",
    "\n",
    "        article_id_info = item.get(\"article_id\", {})\n",
    "        article_id = article_id_info.get(\"Arxiv\", None) if isinstance(article_id_info, dict) else None\n",
    "        refer_id = article_id\n",
    "        \n",
    "        citation_sentences_list = item.get(\"citation_sentences\", [])\n",
    "        grouped_sentences = {}\n",
    "\n",
    "        for citation_sentence in citation_sentences_list:\n",
    "            cite_id = citation_sentence.get(\"cite_id\", None)\n",
    "            citing_sentences_list = citation_sentence.get(\"citing_sentences\", [])\n",
    "\n",
    "            for citing_sentence in citing_sentences_list:\n",
    "                citing_sent = citing_sentence.get(\"sent\", None)\n",
    "                refer_sids = citing_sentence.get(\"id\", None)\n",
    "                label_ref = citing_sentence.get(\"label_ref\", None)\n",
    "                prev_sent = citing_sentence.get(\"sent_before\", None) \n",
    "                next_sent = citing_sentence.get(\"sent_after\", None)  \n",
    "                number += 1\n",
    "\n",
    "                merge_sent = \" \".join(filter(None, [prev_sent, citing_sent, next_sent]))\n",
    "\n",
    "                key = (\n",
    "                    article_id,  # refer_ID\n",
    "                    cite_id,     # cite_ID\n",
    "                    tuple(refer_sids) if refer_sids else None\n",
    "                )\n",
    "\n",
    "                if key not in grouped_sentences:\n",
    "                    grouped_sentences[key] = {\n",
    "                        \"Number\": number,\n",
    "                        \"refer_ID\": article_id,\n",
    "                        \"refer_ids\": refer_sids,\n",
    "                        \"label_ref\": label_ref,\n",
    "                        \"cite_ID\": cite_id,\n",
    "                        \"GPT_cite_text\": citing_sent,\n",
    "                        \"prev_curr_sent\": prev_sent,  # Câu trước\n",
    "                        \"curr_next_sent\": next_sent,  # Câu sau\n",
    "                        \"merge_sent\": merge_sent,\n",
    "                    }\n",
    "                else:\n",
    "                    grouped_sentences[key][\"GPT_cite_text\"] += \" \" + citing_sent\n",
    "\n",
    "        article_citation_sentences.extend(grouped_sentences.values())\n",
    "\n",
    "        if article_citation_sentences:\n",
    "            dicts.append({\n",
    "                \"article_id\": article_id,\n",
    "                \"citation_sentences\": article_citation_sentences\n",
    "            })\n",
    "\n",
    "    with open(file_output, 'w', encoding='utf-8') as jsonfile:\n",
    "        json.dump(dicts, jsonfile, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-22T19:38:19.218177Z",
     "iopub.status.idle": "2025-05-22T19:38:19.218555Z",
     "shell.execute_reply": "2025-05-22T19:38:19.218394Z",
     "shell.execute_reply.started": "2025-05-22T19:38:19.218350Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "input_file = \"label_ref_merged_output_ref_arxiv_author_title.json\"\n",
    "output_file = \"label_ref_arxiv_citation.json\"\n",
    "\n",
    "conv_with_group(input_file, output_file)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
